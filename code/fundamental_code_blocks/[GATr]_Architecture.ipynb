{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install \"datasets\" \"pytorch-lightning\" \"wandb\" \"torcheval\" \"torchmetrics\" \"clifford\""
      ],
      "metadata": {
        "id": "NK9Vzh33EHqO"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import LightningDataModule, LightningModule, Trainer, seed_everything\n",
        "\n",
        "from torchmetrics.classification import BinaryAccuracy\n",
        "from torchmetrics.classification import BinaryPrecision\n",
        "from torchmetrics.classification import BinaryRecall\n",
        "from torchmetrics.classification import BinaryF1Score\n",
        "\n",
        "from clifford import Cl\n"
      ],
      "metadata": {
        "id": "lxFbQPFtEGCA"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# device ="
      ],
      "metadata": {
        "id": "idBYCpx0QZet"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GATr ARCHITECTURE"
      ],
      "metadata": {
        "id": "xd2dhW3y0DwG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Claudio's section\n",
        "---"
      ],
      "metadata": {
        "id": "rA54IKoC0H7K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "BXAvY8ee0C0K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Jacopo's section\n",
        "---"
      ],
      "metadata": {
        "id": "qtZi3zyB0NlR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Auxiliar / dummy"
      ],
      "metadata": {
        "id": "bCvJCYeQlnP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xWjorqYhlkrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_mv = {'': 1.0, 'e1': 1.01, 'e2': 1.02, 'e3': 1.03, 'e4': 1.04, 'e12': 2.01, 'e13': 2.02, 'e14': 2.03, 'e23': 2.04, 'e24': 2.05, 'e34': 2.06,  'e123': 3.01, 'e124': 3.02, 'e134': 3.03,  'e234': 3.04, 'e1234': 5.0}"
      ],
      "metadata": {
        "id": "iy8NQYGClWhO"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_tensor = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5], requires_grad=True)"
      ],
      "metadata": {
        "id": "yq3KE29OL65B"
      },
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compose_multivector(sample):\n",
        "    wss_multivector = 0\n",
        "    for row in sin_sample['wss'][()]:\n",
        "        vector = row[0] * blades[''] + row[1] * blades[''] + row[2] * blades['']\n",
        "        wss_multivector += vector\n",
        "\n",
        "    # pressure as a pseudoscalar\n",
        "    pressure_multivector = 0\n",
        "    for elem in sin_sample['pressure'][()]:\n",
        "        vector = elem * blades['e1234']\n",
        "        pressure_multivector += vector\n",
        "\n",
        "      # pos as a point\n",
        "    pos_multivector = 0\n",
        "    for row in sin_sample['pos'][()]:\n",
        "        vector = row[0] * blades['e123'] + row[1] * blades['e124'] + row[2] * blades['e134']\n",
        "        pos_multivector += vector\n",
        "\n",
        "      # face as a plane\n",
        "    face_multivector = 0\n",
        "    for row in sin_sample['face'][()]:\n",
        "        vector = row[0] * blades['e1'] + row[1] * blades['e2'] + row[2] * blades['e3']\n",
        "        face_multivector += vector\n",
        "\n",
        "      # inlet as a scalar\n",
        "    inlet_multivector = 0\n",
        "    for elem in sin_sample['inlet_idcs'][()]:\n",
        "        vector = elem * blades['']\n",
        "        inlet_multivector += vector\n",
        "\n",
        "\n",
        "    total_multivector = wss_multivector + pressure_multivector + pos_multivector + face_multivector + inlet_multivector\n",
        "    return total_multivector"
      ],
      "metadata": {
        "id": "hGDT469WNsqD"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layers"
      ],
      "metadata": {
        "id": "nLVG3A99ljXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class J_equi_linear(pl.LightningModule):\n",
        "    def __init__(self, mv_dict_type, in_feat=5, out_feat=5, ):\n",
        "        super(J_equi_linear, self).__init__()\n",
        "\n",
        "        self.mv_dict_type = mv_dict_type # indicate if the multivector is expressed as 16 basis or they are all summed up\n",
        "        self.equi_linear_layer = torch.nn.Linear(in_features=in_feat, out_features=out_feat)\n",
        "\n",
        "    def forward(self, multivector):\n",
        "\n",
        "        if self.mv_dict_type == True: # first equivariant layer of the architecture\n",
        "            multivector_basis = list( multivector.keys() )\n",
        "\n",
        "            # summing up all scalars - vectorl - bivectorl - trivectorl - bias ( its '' basis )\n",
        "            bias = 0                     # should be: 1.0\n",
        "            vector_value = 0             # should be: 4.1\n",
        "            bivector_value = 0           # should be: 12.21\n",
        "            trivector_value = 0          # should be: 12.10\n",
        "            pseudoscalar_value = 0       # should be: 5.0\n",
        "\n",
        "            for basis in multivector_basis:\n",
        "                if len(basis) == 2:     vector_value += multivector[basis]\n",
        "                elif len(basis) == 3:   bivector_value += multivector[basis]\n",
        "                elif len(basis) == 4:   trivector_value += multivector[basis]\n",
        "                elif len(basis) == 5:   pseudoscalar_value += multivector[basis]\n",
        "                else:                   bias += multivector[basis]\n",
        "\n",
        "            # check correctness of position of each entries. Maybe switch bias and scalar value (?)\n",
        "            input_tensor = torch.tensor( [ bias, vector_value, bivector_value, trivector_value, pseudoscalar_value ] ,\n",
        "                                            dtype=torch.float32,\n",
        "                                            requires_grad=True\n",
        "                                        )\n",
        "\n",
        "            # check why print 12.2099999 instead of 12.1, can be a problem ?\n",
        "            print(f\"--Analizing input component:\\nbias(''): {bias}\\nvector(e_i): {vector_value}\\nbivector(e_ij): {bivector_value}\\ntrivector(e_ijk): {trivector_value}\\npseudoscalar(e_ijkl): {pseudoscalar_value}\")\n",
        "            print(f\"\\ninput_tensor: {input_tensor}\\n--input's analisys finished. \\n\\n\")\n",
        "        else:\n",
        "            input_tensor = multivector\n",
        "\n",
        "        output = self.equi_linear_layer( input_tensor )\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "my_layer = J_equi_linear(mv_dict_type=True)\n",
        "out = my_layer(dummy_mv)\n",
        "#print(out)"
      ],
      "metadata": {
        "id": "NhztcT6gVwm4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class J_norm_linear(pl.LightningModule):\n",
        "    def __init__(self, normalized_shape = (5,), eps=1e-05):\n",
        "        super(J_norm_linear, self).__init__()\n",
        "\n",
        "        self.normalized_shape = normalized_shape # shape of the tesnor\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, multivector):\n",
        "        output = torch.nn.functional.layer_norm( multivector, self.normalized_shape, eps = self.eps )\n",
        "\n",
        "        return output\n",
        "\n",
        "my_layer = J_norm_linear()"
      ],
      "metadata": {
        "id": "LhF_SF8nsZfH"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class J_geo_attention(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super(J_geo_attention, self).__init__()\n",
        "        #https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html\n",
        "        #https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html\n",
        "\n",
        "        tensor_length = 5\n",
        "        self.key   = nn.Parameter(torch.randn(tensor_length)).unsqueeze(0) # it is correct do it here? it is request to use 2 dimension\n",
        "        self.value = nn.Parameter(torch.randn(tensor_length)).unsqueeze(0)\n",
        "\n",
        "    def forward(self, multivector_query):\n",
        "        multivector_query = multivector_query.unsqueeze(0) # it is request to use 2 dimension\n",
        "        output = torch.nn.functional.scaled_dot_product_attention(multivector_query, self.key, self.value)\n",
        "\n",
        "        return output\n",
        "\n",
        "my_layer = J_geo_attention()"
      ],
      "metadata": {
        "id": "YAitQDS_58TI"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# check the correctness!\n",
        "\n",
        "class J_gated_relu(pl.LightningModule):\n",
        "    def __init__(self, gating_signal):\n",
        "        super(J_gated_relu, self).__init__()\n",
        "\n",
        "        # gelu: https://paperswithcode.com/method/gelu\n",
        "        # gated gelu(x,g) = g*GELU(x) + (1-g)*x  ( from chatgpt )\n",
        "\n",
        "        self.gating_signal = gating_signal\n",
        "\n",
        "    def forward(self, multivector):\n",
        "        multivector = multivector.detach().cpu().numpy()\n",
        "        scalar = multivector[-1] # taking scalar component\n",
        "        cut_multivector = multivector[:-1] # exlude last element\n",
        "\n",
        "        x = cut_multivector\n",
        "\n",
        "        argument_tanh = np.sqrt(2/np.pi) * (x + 0.044715 * np.power(x,3)  )\n",
        "        gelu_value = 0.5 * x * ( 1.0 + np.tanh(argument_tanh) )\n",
        "\n",
        "        g = self.gating_signal\n",
        "        output = g * gelu_value + (1-g)*x\n",
        "        output = output*scalar\n",
        "\n",
        "        output = np.append(output, scalar) # to match the dimension, check it!\n",
        "\n",
        "        output = torch.tensor(output, requires_grad=True)\n",
        "        return output\n",
        "\n",
        "my_layer = J_gated_relu(0.7)\n",
        "out = my_layer(dummy_tensor)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xspzAy_uKqgS",
        "outputId": "87e1a1f6-28d5-413d-8a68-54ee416e0631"
      },
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([0.0339, 0.0705, 0.1099, 0.1518, 0.5000], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class J_geo_bilin_TODO(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super()\n",
        "        #super(J_geo_bilin, self).__init__()\n",
        "\n",
        "    def forward(self, multivector):\n",
        "        output = ...\n",
        "\n",
        "        return output\n",
        "\n",
        "my_layer = J_norm_linear()"
      ],
      "metadata": {
        "id": "cb1p8wzIK1U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class J_gatr(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        #self.device = must run on cpu and gpu, create first block with device cell\n",
        "        self.gating_signal = 0.7\n",
        "\n",
        "        # input layer: in = input\n",
        "        self.in_equi_linear_layer = J_equi_linear(in_feat=5, out_feat=5, mv_dict_type=True )\n",
        "\n",
        "        # first half block: h1 = first half\n",
        "        self.h1_norm_linear_layer   = J_norm_linear(normalized_shape=(5,))\n",
        "        self.h1_equi_linear_layer_1 = J_equi_linear(in_feat=5, out_feat=5, mv_dict_type=False )\n",
        "        self.h1_att_layer           = J_geo_attention()\n",
        "        self.h1_equi_linear_layer_2 = J_equi_linear(in_feat=5, out_feat=5, mv_dict_type=False )\n",
        "\n",
        "        # second half block: h2 = second half\n",
        "        self.h2_norm_linear_layer   = J_norm_linear(normalized_shape=(5,))\n",
        "        self.h2_equi_linear_layer_1 = J_equi_linear(in_feat=5, out_feat=5, mv_dict_type=False )\n",
        "        #self.h2_geo_bilinear_layer  = J_geo_bilin()\n",
        "        self.h2_gated_relu_layer    = J_gated_relu( gating_signal=self.gating_signal )\n",
        "        self.h2_equi_linear_layer_2 = J_equi_linear(in_feat=5, out_feat=5, mv_dict_type=False )\n",
        "\n",
        "\n",
        "        # output layer out = output\n",
        "        self.out_equi_linear_layer = J_equi_linear(in_feat=5, out_feat=5, mv_dict_type=False)\n",
        "\n",
        "        # metrics\n",
        "        self.accuracy_metric  = BinaryAccuracy()\n",
        "        self.precision_metric = BinaryPrecision()\n",
        "        self.recall_metric    = BinaryRecall()\n",
        "        self.f1score_metric   = BinaryF1Score()\n",
        "\n",
        "\n",
        "    def forward(self, multivector):\n",
        "        do_print = True\n",
        "\n",
        "        print(f\"input: {multivector.values()}\\n\\nFirst block\")\n",
        "        # input layer\n",
        "        in_out_eq  = self.in_equi_linear_layer(multivector);       print(f\"in_out_eq: {in_out_eq}\")\n",
        "\n",
        "        # first half block\n",
        "        print(f\"\\n\\nFirstblock\")\n",
        "        h1_out_norm = self.h1_norm_linear_layer( in_out_eq );        print(f\"h1_out_norm: {h1_out_norm}\")\n",
        "        h1_out_eq_1 = self.h1_equi_linear_layer_1( h1_out_norm );    print(f\"h1_out_eq_1: {h1_out_eq_1}\")\n",
        "        h1_out_att  = self.h1_att_layer( h1_out_eq_1 ).squeeze();    print(f\"h1_out_att : {h1_out_att}\") # I output I have [[...]], I think is better have [...]\n",
        "        h1_out_eq_2 = self.h1_equi_linear_layer_2( h1_out_att );     print(f\"h1_out_eq_2: {h1_out_eq_2}\")\n",
        "\n",
        "        # second half block\n",
        "        print(f\"\\n\\nSecond block\")\n",
        "        h2_out_norm       = self.h2_norm_linear_layer( h1_out_eq_2 + in_out_eq );   print(f\"h2_out_norm:       {h2_out_norm}\")\n",
        "        h2_out_eq_1       = self.h2_equi_linear_layer_1( h2_out_norm );             print(f\"h2_out_eq_1:       {h2_out_eq_1}\")\n",
        "        h2_out_geo_bilin  = h2_out_eq_1 #self.h2_geo_bilinear_layer( h2_out_eq_1 );              print(f\"h2_out_geo_bilin:  {h2_out_geo_bilin}\")\n",
        "        h2_out_gated_relu = self.h2_gated_relu_layer( h2_out_geo_bilin );           print(f\"h2_out_gated_relu: {h2_out_gated_relu}\")\n",
        "        h2_out_eq_2       = self.h2_equi_linear_layer_2( h2_out_gated_relu );       print(f\"h2_out_eq_2:       {h2_out_eq_2}\")\n",
        "\n",
        "\n",
        "        # output of the whole block\n",
        "        output_block = h2_out_eq_2 + ( in_out_eq + h1_out_eq_2 ); print(f\"output_block: {output_block}\")\n",
        "        #here we could 2 things:\n",
        "        # - added the scalar component at gated_relu to pass from shape 4 to 5 ( which I have done)\n",
        "        # - to this addition adding withouth tensor, so summing up with list the first 4 component and last one\n",
        "\n",
        "\n",
        "        # output layer\n",
        "        print(\"\\n\\nOutput block\")\n",
        "        output = self.out_equi_linear_layer(output_block);   print(f\"gatr_output: {output}\")\n",
        "\n",
        "        return output\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        x, y = batch\n",
        "\n",
        "        # check if the used loss is correct according to the paper, find it on the github\n",
        "        loss = F.binary_cross_entropy(x, y) # In case we need to adjust dimension\n",
        "        #loss = F.binary_cross_entropy(self(x).view(-1), y.float())\n",
        "\n",
        "        #predictions = self.forward(x).long().squeeze()\n",
        "        #y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "        #accuracy  = accuracy(predictions, y)\n",
        "        #precision = self.precision_metric(predictions, y)\n",
        "        #recall    = self.recall_metric(predictions, y)\n",
        "        #f1_score  = self.f1_metric(predictions, y)\n",
        "\n",
        "        #wandb.log({\"acc\": accuracy,\"loss\": loss,\"precision\": precision, \"recall\": recall, \"f1-score:\":f1_score })\n",
        "\n",
        "        return loss\n",
        "\n",
        "    '''\n",
        "    # look at https://colab.research.google.com/drive/1lUIrtEiQN9hA5RIdKTpUS7w5gI1DLvOl#scrollTo=gigZq4h0yifA\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return None\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return None\n",
        "    '''\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.02)\n",
        "\n",
        "gatr_j = J_gatr()"
      ],
      "metadata": {
        "id": "XYJ6UsYF0RqA"
      },
      "execution_count": 124,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = gatr_j(dummy_mv)\n",
        "print(f\"\\noutput: {out}\")"
      ],
      "metadata": {
        "id": "ATUvJW7mqMH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40d94bf3-e68a-4ca7-dc1f-c16715f32d91"
      },
      "execution_count": 125,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: dict_values([1.0, 1.01, 1.02, 1.03, 1.04, 2.01, 2.02, 2.03, 2.04, 2.05, 2.06, 3.01, 3.02, 3.03, 3.04, 5.0])\n",
            "\n",
            "First block\n",
            "--Analizing input component:\n",
            "bias(''): 1.0\n",
            "vector(e_i): 4.1000000000000005\n",
            "bivector(e_ij): 12.209999999999999\n",
            "trivector(e_ijk): 12.099999999999998\n",
            "pseudoscalar(e_ijkl): 5.0\n",
            "\n",
            "input_tensor: tensor([ 1.0000,  4.1000, 12.2100, 12.1000,  5.0000], requires_grad=True)\n",
            "--input's analisys finished. \n",
            "\n",
            "\n",
            "in_out_eq: tensor([-3.2924, -5.4442, -1.9412,  8.2329, -0.3314], grad_fn=<ViewBackward0>)\n",
            "\n",
            "\n",
            "Firstblock\n",
            "h1_out_norm: tensor([-0.5820, -1.0395, -0.2947,  1.8686,  0.0476],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "h1_out_eq_1: tensor([-0.8506,  1.4924, -0.7847, -0.6410,  0.9160], grad_fn=<ViewBackward0>)\n",
            "h1_out_att : tensor([ 1.5032,  0.4592,  0.2753, -1.4815, -1.0331],\n",
            "       grad_fn=<SqueezeBackward0>)\n",
            "h1_out_eq_2: tensor([-0.1239,  0.5294, -0.2160,  1.1195,  1.0141], grad_fn=<ViewBackward0>)\n",
            "\n",
            "\n",
            "Second block\n",
            "h2_out_norm:       tensor([-0.6563, -0.9521, -0.4078,  1.8636,  0.1526],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "h2_out_eq_1:       tensor([-0.0385,  0.9943,  0.5330,  0.3333, -0.3724], grad_fn=<ViewBackward0>)\n",
            "h2_out_gated_relu: tensor([ 0.0092, -0.3288, -0.1572, -0.0920, -0.3724], requires_grad=True)\n",
            "h2_out_eq_2:       tensor([0.0582, 0.0333, 0.1584, 0.1382, 0.0063], grad_fn=<ViewBackward0>)\n",
            "output_block: tensor([-3.3581, -4.8815, -1.9988,  9.4906,  0.6890], grad_fn=<AddBackward0>)\n",
            "\n",
            "\n",
            "Output block\n",
            "gatr_output: tensor([ 1.2345,  2.1057, -1.7118,  3.8159,  0.7367], grad_fn=<ViewBackward0>)\n",
            "\n",
            "output: tensor([ 1.2345,  2.1057, -1.7118,  3.8159,  0.7367], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Lorenzo's section\n",
        "---"
      ],
      "metadata": {
        "id": "3YDBpEMO0RVC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MQJH2MT40U_E"
      },
      "execution_count": 35,
      "outputs": []
    }
  ]
}