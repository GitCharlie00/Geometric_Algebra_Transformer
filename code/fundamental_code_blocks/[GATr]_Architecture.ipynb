{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "! pip install \"datasets\" \"pytorch-lightning\" \"wandb\" \"torcheval\" \"torchmetrics\" \"clifford\" \"torch-geometric\""
      ],
      "metadata": {
        "id": "NK9Vzh33EHqO"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "\n",
        "#import torch_geometric.nn\n",
        "\n",
        "import pytorch_lightning as pl\n",
        "from pytorch_lightning import LightningDataModule, LightningModule, Trainer, seed_everything\n",
        "\n",
        "from torchmetrics.classification import BinaryAccuracy\n",
        "from torchmetrics.classification import BinaryPrecision\n",
        "from torchmetrics.classification import BinaryRecall\n",
        "from torchmetrics.classification import BinaryF1Score\n",
        "\n",
        "from clifford import Cl\n"
      ],
      "metadata": {
        "id": "lxFbQPFtEGCA"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "use_cuda = torch.cuda.is_available()\n",
        "device   = torch.device(\"cuda\" if use_cuda else \"cpu\")"
      ],
      "metadata": {
        "id": "idBYCpx0QZet"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# GATr ARCHITECTURE"
      ],
      "metadata": {
        "id": "xd2dhW3y0DwG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Claudio's section\n",
        "---"
      ],
      "metadata": {
        "id": "rA54IKoC0H7K"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "BXAvY8ee0C0K"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Jacopo's section\n",
        "---"
      ],
      "metadata": {
        "id": "qtZi3zyB0NlR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Auxiliar / dummy"
      ],
      "metadata": {
        "id": "bCvJCYeQlnP8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "xWjorqYhlkrP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_mv = {'': 1.0, 'e1': 1.01, 'e2': 1.02, 'e3': 1.03, 'e4': 1.04, 'e12': 2.01, 'e13': 2.02, 'e14': 2.03, 'e23': 2.04, 'e24': 2.05, 'e34': 2.06,  'e123': 3.01, 'e124': 3.02, 'e134': 3.03,  'e234': 3.04, 'e1234': 5.0}"
      ],
      "metadata": {
        "id": "iy8NQYGClWhO"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_tensor = torch.tensor([0.1, 0.2, 0.3, 0.4, 0.5], requires_grad=True)"
      ],
      "metadata": {
        "id": "yq3KE29OL65B"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dummy_matrix = torch.tensor([[-0.0281, -0.0399,  0.0262, -0.0089],\n",
        "        [-0.0399, -0.0567,  0.0373, -0.0127],\n",
        "        [ 0.0262,  0.0373, -0.0245,  0.0083],\n",
        "        [-0.0089, -0.0127,  0.0083, -0.0028]], requires_grad=True)"
      ],
      "metadata": {
        "id": "9QXhizujnQI0"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compose_multivector(sample):\n",
        "    wss_multivector = 0\n",
        "    for row in sin_sample['wss'][()]:\n",
        "        vector = row[0] * blades[''] + row[1] * blades[''] + row[2] * blades['']\n",
        "        wss_multivector += vector\n",
        "\n",
        "    # pressure as a pseudoscalar\n",
        "    pressure_multivector = 0\n",
        "    for elem in sin_sample['pressure'][()]:\n",
        "        vector = elem * blades['e1234']\n",
        "        pressure_multivector += vector\n",
        "\n",
        "      # pos as a point\n",
        "    pos_multivector = 0\n",
        "    for row in sin_sample['pos'][()]:\n",
        "        vector = row[0] * blades['e123'] + row[1] * blades['e124'] + row[2] * blades['e134']\n",
        "        pos_multivector += vector\n",
        "\n",
        "      # face as a plane\n",
        "    face_multivector = 0\n",
        "    for row in sin_sample['face'][()]:\n",
        "        vector = row[0] * blades['e1'] + row[1] * blades['e2'] + row[2] * blades['e3']\n",
        "        face_multivector += vector\n",
        "\n",
        "      # inlet as a scalar\n",
        "    inlet_multivector = 0\n",
        "    for elem in sin_sample['inlet_idcs'][()]:\n",
        "        vector = elem * blades['']\n",
        "        inlet_multivector += vector\n",
        "\n",
        "\n",
        "    total_multivector = wss_multivector + pressure_multivector + pos_multivector + face_multivector + inlet_multivector\n",
        "    return total_multivector"
      ],
      "metadata": {
        "id": "hGDT469WNsqD"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Layers"
      ],
      "metadata": {
        "id": "nLVG3A99ljXG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class J_equi_linear(pl.LightningModule):\n",
        "    def __init__(self, mv_dict_type, in_feat=5, out_feat=5, ):\n",
        "        super(J_equi_linear, self).__init__()\n",
        "\n",
        "        self.mv_dict_type = mv_dict_type # indicate if the multivector is expressed as 16 basis or they are all summed up\n",
        "        self.equi_linear_layer = torch.nn.Linear(in_features=in_feat, out_features=out_feat)\n",
        "\n",
        "    def forward(self, multivector):\n",
        "\n",
        "        if self.mv_dict_type == True: # first equivariant layer of the architecture\n",
        "            multivector_basis = list( multivector.keys() )\n",
        "\n",
        "            # summing up all scalars - vectorl - bivectorl - trivectorl - bias ( its '' basis )\n",
        "            bias = 0                     # should be: 1.0\n",
        "            vector_value = 0             # should be: 4.1\n",
        "            bivector_value = 0           # should be: 12.21\n",
        "            trivector_value = 0          # should be: 12.10\n",
        "            pseudoscalar_value = 0       # should be: 5.0\n",
        "\n",
        "            for basis in multivector_basis:\n",
        "                if len(basis) == 2:     vector_value += multivector[basis]\n",
        "                elif len(basis) == 3:   bivector_value += multivector[basis]\n",
        "                elif len(basis) == 4:   trivector_value += multivector[basis]\n",
        "                elif len(basis) == 5:   pseudoscalar_value += multivector[basis]\n",
        "                else:                   bias += multivector[basis]\n",
        "\n",
        "            # check correctness of position of each entries. Maybe switch bias and scalar value (?)\n",
        "            input_tensor = torch.tensor( [ bias, vector_value, bivector_value, trivector_value, pseudoscalar_value ] ,\n",
        "                                            dtype=torch.float32,\n",
        "                                            requires_grad=True\n",
        "                                        )\n",
        "\n",
        "            # check why print 12.2099999 instead of 12.1, can be a problem ?\n",
        "            #print(f\"--Analizing input component:\\nbias(''): {bias}\\nvector(e_i): {vector_value}\\nbivector(e_ij): {bivector_value}\\ntrivector(e_ijk): {trivector_value}\\npseudoscalar(e_ijkl): {pseudoscalar_value}\")\n",
        "            #print(f\"\\ninput_tensor: {input_tensor}\\n--input's analisys finished. \\n\\n\")\n",
        "        else:\n",
        "            input_tensor = multivector\n",
        "\n",
        "        output = self.equi_linear_layer( input_tensor )\n",
        "\n",
        "        return output\n",
        "\n",
        "\n",
        "my_layer1 = J_equi_linear(mv_dict_type=True)\n",
        "out = my_layer1(dummy_mv)\n",
        "print(out)\n",
        "\n",
        "my_layer2 = J_equi_linear(mv_dict_type=False)\n",
        "out2 = my_layer2(dummy_tensor)\n",
        "print(out2)"
      ],
      "metadata": {
        "id": "NhztcT6gVwm4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02ba424e-3518-4d4b-d700-d2457411ac1b"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([ 0.5496, -5.0536,  0.8110, -3.9570,  1.7721], grad_fn=<ViewBackward0>)\n",
            "tensor([ 0.2753, -0.2292,  0.1056,  0.2185,  0.5455], grad_fn=<ViewBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class J_norm_linear(pl.LightningModule):\n",
        "    def __init__(self, normalized_shape = (5,), eps=1e-05):\n",
        "        super(J_norm_linear, self).__init__()\n",
        "\n",
        "        self.normalized_shape = normalized_shape # shape of the tesnor\n",
        "        self.eps = eps\n",
        "\n",
        "    def forward(self, multivector):\n",
        "        output = torch.nn.functional.layer_norm( multivector, self.normalized_shape, eps = self.eps )\n",
        "\n",
        "        return output\n",
        "\n",
        "my_layer = J_norm_linear()\n",
        "out = my_layer(dummy_tensor)\n",
        "#print(out)"
      ],
      "metadata": {
        "id": "LhF_SF8nsZfH"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class J_geo_attention(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super(J_geo_attention, self).__init__()\n",
        "        #https://pytorch.org/docs/stable/generated/torch.nn.functional.scaled_dot_product_attention.html\n",
        "        #https://pytorch.org/docs/stable/generated/torch.nn.MultiheadAttention.html\n",
        "\n",
        "        tensor_length = 5\n",
        "        self.key   = nn.Parameter(torch.randn(tensor_length)).unsqueeze(0) # it is correct do it here? it is request to use 2 dimension\n",
        "        self.value = nn.Parameter(torch.randn(tensor_length)).unsqueeze(0)\n",
        "\n",
        "    def forward(self, multivector_query):\n",
        "        multivector_query = multivector_query.unsqueeze(0) # it is request to use 2 dimension\n",
        "        output = torch.nn.functional.scaled_dot_product_attention(multivector_query, self.key, self.value)\n",
        "\n",
        "        return output\n",
        "\n",
        "my_layer = J_geo_attention()\n",
        "out = my_layer(dummy_tensor)\n",
        "print(out)"
      ],
      "metadata": {
        "id": "YAitQDS_58TI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "543a059b-afb0-43a4-d5d1-7d5370fde584"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 1.0811,  0.7897, -0.0917,  0.4805, -1.5568]], grad_fn=<MmBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the correctness!\n",
        "\n",
        "class J_gated_relu(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super(J_gated_relu, self).__init__()\n",
        "\n",
        "        # gelu: https://paperswithcode.com/method/gelu\n",
        "        # gated_gelu(x,g) = g*GELU(x) + (1-g)*x  ( from chatgpt )\n",
        "\n",
        "        self.gelu_fn = nn.GELU()\n",
        "\n",
        "    def forward(self, multivector):\n",
        "\n",
        "        scalar = torch.tensor(multivector[:, 0]) # taking scalar component\n",
        "        #cut_multivector = torch.tensor(multivector[:,1:]) # exlude first elemnt ( scalar )\n",
        "\n",
        "        gelu_value = self.gelu_fn(scalar)\n",
        "        output = gelu_value * multivector\n",
        "\n",
        "        return output\n",
        "\n",
        "my_layer = J_gated_relu()\n",
        "out = my_layer(dummy_matrix)\n",
        "#print(out)"
      ],
      "metadata": {
        "id": "xspzAy_uKqgS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c35022e8-66a7-4021-acf6-96470aff8a44"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-a904f204d5d5>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  scalar = torch.tensor(multivector[:, 0]) # taking scalar component\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class J_geo_bilin(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super(J_geo_bilin, self).__init__()\n",
        "\n",
        "    def forward(self, multivector):\n",
        "        scalar = multivector[-1] # taking pseudoscalar component\n",
        "        #cut_multivector = multivector[:-1] # exlude last element\n",
        "\n",
        "        transposed_multivector = multivector.t()\n",
        "        inner_product = torch.matmul( multivector, transposed_multivector )\n",
        "        outer_product = torch.ger( transposed_multivector, multivector )\n",
        "\n",
        "        output = scalar * outer_product\n",
        "        return output\n",
        "\n",
        "my_layer = J_geo_bilin()\n",
        "out = my_layer(dummy_tensor)\n",
        "print(out)"
      ],
      "metadata": {
        "id": "cb1p8wzIK1U3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class J_gatr(pl.LightningModule):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "        #self.device = must run on cpu and gpu, create first block with device cell\n",
        "\n",
        "        # input layer: in = input\n",
        "        self.in_equi_linear_layer = J_equi_linear(in_feat=5, out_feat=5, mv_dict_type=True )\n",
        "\n",
        "        # first half block: h1 = first half\n",
        "        self.h1_norm_linear_layer   = J_norm_linear(normalized_shape=(5,))\n",
        "        self.h1_equi_linear_layer_1 = J_equi_linear(in_feat=5, out_feat=5, mv_dict_type=False )\n",
        "        self.h1_att_layer           = J_geo_attention()\n",
        "        self.h1_equi_linear_layer_2 = J_equi_linear(in_feat=5, out_feat=5, mv_dict_type=False )\n",
        "\n",
        "        # second half block: h2 = second half\n",
        "        self.h2_norm_linear_layer   = J_norm_linear(normalized_shape=(5,))\n",
        "        self.h2_equi_linear_layer_1 = J_equi_linear(in_feat=5, out_feat=5, mv_dict_type=False )\n",
        "        self.h2_geo_bilinear_layer  = J_geo_bilin()\n",
        "        self.h2_gated_relu_layer    = J_gated_relu()\n",
        "        self.h2_equi_linear_layer_2 = J_equi_linear(in_feat=5, out_feat=5, mv_dict_type=False )\n",
        "\n",
        "\n",
        "        # output layer out = output\n",
        "        self.out_equi_linear_layer = J_equi_linear(in_feat=5, out_feat=5, mv_dict_type=False)\n",
        "\n",
        "        # metrics\n",
        "        self.accuracy_metric  = BinaryAccuracy()\n",
        "        self.precision_metric = BinaryPrecision()\n",
        "        self.recall_metric    = BinaryRecall()\n",
        "        self.f1score_metric   = BinaryF1Score()\n",
        "\n",
        "\n",
        "    def forward(self, multivector):\n",
        "        do_print = True\n",
        "\n",
        "        print(f\"input: {multivector.values()}\\n\\nFirst block\")\n",
        "        # input layer\n",
        "        in_out_eq  = self.in_equi_linear_layer(multivector);       print(f\"in_out_eq: {in_out_eq}\")\n",
        "\n",
        "        # first half block\n",
        "        print(f\"\\n\\nFirstblock\")\n",
        "        h1_out_norm = self.h1_norm_linear_layer( in_out_eq );        print(f\"h1_out_norm: {h1_out_norm}\")\n",
        "        h1_out_eq_1 = self.h1_equi_linear_layer_1( h1_out_norm );    print(f\"h1_out_eq_1: {h1_out_eq_1}\")\n",
        "        h1_out_att  = self.h1_att_layer( h1_out_eq_1 ).squeeze();    print(f\"h1_out_att : {h1_out_att}\") # I output I have [[...]], I think is better have [...]\n",
        "        h1_out_eq_2 = self.h1_equi_linear_layer_2( h1_out_att );     print(f\"h1_out_eq_2: {h1_out_eq_2}\")\n",
        "\n",
        "        # second half block\n",
        "        print(f\"\\n\\nSecond block\")\n",
        "        h2_out_norm       = self.h2_norm_linear_layer( h1_out_eq_2 + in_out_eq );   print(f\"h2_out_norm:       {h2_out_norm}\")\n",
        "        h2_out_eq_1       = self.h2_equi_linear_layer_1( h2_out_norm );             print(f\"h2_out_eq_1:       {h2_out_eq_1}\")\n",
        "        h2_out_geo_bilin  = self.h2_geo_bilinear_layer( h2_out_eq_1 );              print(f\"h2_out_geo_bilin:  {h2_out_geo_bilin}\")\n",
        "        #h2_out_geo_bilin  = h2_out_eq_1 # dummy\n",
        "        h2_out_gated_relu = self.h2_gated_relu_layer( h2_out_geo_bilin );           print(f\"h2_out_gated_relu: {h2_out_gated_relu}\")\n",
        "        h2_out_eq_2       = self.h2_equi_linear_layer_2( h2_out_gated_relu );       print(f\"h2_out_eq_2:       {h2_out_eq_2}\")\n",
        "\n",
        "\n",
        "        # output of the whole block\n",
        "        output_block = h2_out_eq_2 + ( in_out_eq + h1_out_eq_2 ); print(f\"output_block: {output_block}\")\n",
        "        #here we could 2 things:\n",
        "        # - added the scalar component at gated_relu to pass from shape 4 to 5 ( which I have done)\n",
        "        # - to this addition adding withouth tensor, so summing up with list the first 4 component and last one\n",
        "\n",
        "\n",
        "        # output layer\n",
        "        print(\"\\n\\nOutput block\")\n",
        "        output = self.out_equi_linear_layer(output_block);   print(f\"gatr_output: {output}\")\n",
        "\n",
        "        return output\n",
        "\n",
        "    def training_step(self, batch):\n",
        "        x, y = batch\n",
        "\n",
        "        # check if the used loss is correct according to the paper, find it on the github\n",
        "        loss = F.binary_cross_entropy(x, y) # In case we need to adjust dimension\n",
        "        #loss = F.binary_cross_entropy(self(x).view(-1), y.float())\n",
        "\n",
        "        #predictions = self.forward(x).long().squeeze()\n",
        "        #y = torch.tensor(y, dtype=torch.long)\n",
        "\n",
        "        #accuracy  = accuracy(predictions, y)\n",
        "        #precision = self.precision_metric(predictions, y)\n",
        "        #recall    = self.recall_metric(predictions, y)\n",
        "        #f1_score  = self.f1_metric(predictions, y)\n",
        "\n",
        "        #wandb.log({\"acc\": accuracy,\"loss\": loss,\"precision\": precision, \"recall\": recall, \"f1-score:\":f1_score })\n",
        "\n",
        "        return loss\n",
        "\n",
        "    '''\n",
        "    # look at https://colab.research.google.com/drive/1lUIrtEiQN9hA5RIdKTpUS7w5gI1DLvOl#scrollTo=gigZq4h0yifA\n",
        "    def validation_step(self, batch, batch_idx):\n",
        "        return None\n",
        "\n",
        "    def test_step(self, batch, batch_idx):\n",
        "        return None\n",
        "    '''\n",
        "    def configure_optimizers(self):\n",
        "        return torch.optim.Adam(self.parameters(), lr=0.02)\n",
        "\n",
        "gatr_j = J_gatr()"
      ],
      "metadata": {
        "id": "XYJ6UsYF0RqA"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "out = gatr_j(dummy_mv)\n",
        "print(f\"\\noutput: {out}\")"
      ],
      "metadata": {
        "id": "ATUvJW7mqMH7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2da3782d-d679-4c8c-fecb-a330a3297389"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "input: dict_values([1.0, 1.01, 1.02, 1.03, 1.04, 2.01, 2.02, 2.03, 2.04, 2.05, 2.06, 3.01, 3.02, 3.03, 3.04, 5.0])\n",
            "\n",
            "First block\n",
            "in_out_eq: tensor([-1.2836, -0.1197, -4.2580, -8.2513, -5.5661], grad_fn=<ViewBackward0>)\n",
            "\n",
            "\n",
            "Firstblock\n",
            "h1_out_norm: tensor([ 0.8910,  1.2880, -0.1236, -1.4857, -0.5698],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "h1_out_eq_1: tensor([-1.1693,  0.8410, -0.2879,  0.6833, -1.0619], grad_fn=<ViewBackward0>)\n",
            "h1_out_att : tensor([ 0.3529, -1.8721,  0.2947, -0.8392,  0.5916],\n",
            "       grad_fn=<SqueezeBackward0>)\n",
            "h1_out_eq_2: tensor([-0.2722,  0.2284, -0.7427,  0.0522, -0.1119], grad_fn=<ViewBackward0>)\n",
            "\n",
            "\n",
            "Second block\n",
            "h2_out_norm:       tensor([ 0.8431,  1.4024, -0.3144, -1.3891, -0.5420],\n",
            "       grad_fn=<NativeLayerNormBackward0>)\n",
            "h2_out_eq_1:       tensor([ 0.0808, -0.4473, -0.6555,  0.1801, -0.4252], grad_fn=<ViewBackward0>)\n",
            "h2_out_geo_bilin:  tensor([[-0.0028,  0.0154,  0.0225, -0.0062,  0.0146],\n",
            "        [ 0.0154, -0.0851, -0.1247,  0.0343, -0.0809],\n",
            "        [ 0.0225, -0.1247, -0.1827,  0.0502, -0.1185],\n",
            "        [-0.0062,  0.0343,  0.0502, -0.0138,  0.0326],\n",
            "        [ 0.0146, -0.0809, -0.1185,  0.0326, -0.0769]], grad_fn=<MulBackward0>)\n",
            "h2_out_gated_relu: tensor([[ 3.8392e-06,  1.1943e-04,  2.5795e-04,  1.9035e-05,  1.0787e-04],\n",
            "        [-2.1260e-05, -6.6137e-04, -1.4284e-03, -1.0541e-04, -5.9732e-04],\n",
            "        [-3.1156e-05, -9.6924e-04, -2.0933e-03, -1.5447e-04, -8.7537e-04],\n",
            "        [ 8.5603e-06,  2.6630e-04,  5.7515e-04,  4.2442e-05,  2.4051e-04],\n",
            "        [-2.0210e-05, -6.2872e-04, -1.3579e-03, -1.0020e-04, -5.6783e-04]],\n",
            "       grad_fn=<MulBackward0>)\n",
            "h2_out_eq_2:       tensor([[-0.1314,  0.1288, -0.0709, -0.1002,  0.4395],\n",
            "        [-0.1319,  0.1288, -0.0710, -0.0991,  0.4400],\n",
            "        [-0.1321,  0.1288, -0.0710, -0.0987,  0.4403],\n",
            "        [-0.1314,  0.1288, -0.0708, -0.1004,  0.4394],\n",
            "        [-0.1319,  0.1288, -0.0710, -0.0992,  0.4400]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "output_block: tensor([[-1.6872,  0.2375, -5.0716, -8.2994, -5.2386],\n",
            "        [-1.6877,  0.2375, -5.0717, -8.2983, -5.2380],\n",
            "        [-1.6879,  0.2375, -5.0718, -8.2979, -5.2378],\n",
            "        [-1.6872,  0.2375, -5.0716, -8.2996, -5.2387],\n",
            "        [-1.6877,  0.2375, -5.0717, -8.2984, -5.2381]], grad_fn=<AddBackward0>)\n",
            "\n",
            "\n",
            "Output block\n",
            "gatr_output: tensor([[ 4.5270, -0.3224,  2.8604,  4.4062,  0.4536],\n",
            "        [ 4.5270, -0.3226,  2.8597,  4.4055,  0.4539],\n",
            "        [ 4.5270, -0.3226,  2.8595,  4.4052,  0.4539],\n",
            "        [ 4.5270, -0.3224,  2.8605,  4.4063,  0.4536],\n",
            "        [ 4.5270, -0.3226,  2.8598,  4.4055,  0.4538]],\n",
            "       grad_fn=<AddmmBackward0>)\n",
            "\n",
            "output: tensor([[ 4.5270, -0.3224,  2.8604,  4.4062,  0.4536],\n",
            "        [ 4.5270, -0.3226,  2.8597,  4.4055,  0.4539],\n",
            "        [ 4.5270, -0.3226,  2.8595,  4.4052,  0.4539],\n",
            "        [ 4.5270, -0.3224,  2.8605,  4.4063,  0.4536],\n",
            "        [ 4.5270, -0.3226,  2.8598,  4.4055,  0.4538]],\n",
            "       grad_fn=<AddmmBackward0>)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-a904f204d5d5>:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "  scalar = torch.tensor(multivector[:, 0]) # taking scalar component\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "## Lorenzo's section\n",
        "---"
      ],
      "metadata": {
        "id": "3YDBpEMO0RVC"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MQJH2MT40U_E"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}